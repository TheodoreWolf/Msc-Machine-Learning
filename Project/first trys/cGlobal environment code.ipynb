{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81791f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "from gym import Env\n",
    "from collections import OrderedDict\n",
    "import mpl_toolkits.mplot3d as plt3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "\n",
    "import heapq as hq\n",
    "import functools as ft\n",
    "import operator as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d7758ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INFTY_SIGN = u\"\\u221E\"\n",
    "\n",
    "\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 16\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "    \n",
    "\n",
    "from inspect import currentframe, getframeinfo\n",
    "\n",
    "def get_linenumber():\n",
    "    print_debug_info()\n",
    "    print(\"Line: \")\n",
    "    cf = currentframe()\n",
    "    return cf.f_back.f_lineno\n",
    "\n",
    "def print_debug_info():\n",
    "    frameinfo = getframeinfo(currentframe())\n",
    "    print (\"File: \", frameinfo.filename)\n",
    "    \n",
    "@np.vectorize\n",
    "def compactification(x, x_mid):\n",
    "    if x == 0:\n",
    "        return 0.\n",
    "    if x == np.infty:\n",
    "        return 1.\n",
    "    return x / (x + x_mid)\n",
    "\n",
    "@np.vectorize\n",
    "def inv_compactification(y, x_mid):\n",
    "    if y == 0:\n",
    "        return 0.\n",
    "    if np.allclose(y, 1):\n",
    "        return np.infty\n",
    "    return x_mid * y / (1 - y)\n",
    "\n",
    "class cG_LAGTPKS_Environment(Env):\n",
    "    \"\"\"\n",
    "    This Environment describes the 7D implementation of the copan:GLOBAL model developed by Jobst Heitzig.\n",
    "    The parameters are taken from Nitzbon et al. 2017. \n",
    "    The code contains implementation parts that go back to Jan Nitzbon 2016 \n",
    "    Dynamic variables are :\n",
    "        - terrestrial (\"land\") carbon L\n",
    "        - excess atmospheric carbon stock A\n",
    "        - geological carbon G\n",
    "        - temperature T\n",
    "        - population P\n",
    "        - capital K\n",
    "        - the renewable energy knowledge stock S\n",
    "    \n",
    "    Parameters (mainly Nitzbon et al. 2016 )\n",
    "    ----------\n",
    "        - sim_time: Timestep that will be integrated in this simulation step\n",
    "          In each grid point the agent can choose between subsidy None, A, B or A and B in combination. \n",
    "        - Sigma = 1.5 * 1e8\n",
    "        - CstarPI=4000\n",
    "        - Cstar=5500\n",
    "        - a0=0.03\n",
    "        - aT=3.2*1e3\n",
    "        - l0=26.4\n",
    "        - lT=1.1*1e6\n",
    "        - delta=0.01\n",
    "        - m=1.5\n",
    "        - g=0.02\n",
    "        - p=0.04\n",
    "        - Wp=2000\n",
    "        - q0=20\n",
    "        - b=5.4*1e-7\n",
    "        - yE=147\n",
    "        - eB=4*1e10\n",
    "        - eF=4*1e10\n",
    "        - i=0.25\n",
    "        - k0=0.1\n",
    "        - aY=0.\n",
    "        - aB= 3e5 (varied, basic year 2000)\n",
    "        - aF= 5e6 (varied, basic year 2000)\n",
    "        - aR= 7e-18 (varied, basic year 2000)\n",
    "        - sS=1./50.\n",
    "        - sR=1.\n",
    "    \"\"\"\n",
    "    management_options=['default', \n",
    "                        'Sub' , 'Tax','NP' ,\n",
    "                        'Sub+Tax', 'Sub+NP', 'Tax+NP',\n",
    "                        'Sub+Tax+NP' ]\n",
    "\n",
    "    action_space=[(False, False, False), \n",
    "                        (True, False,False), (False, True, False), (False, False, True),\n",
    "                        (True, True, False), (True, False, True) , (False, True, True),\n",
    "                        (True, True, True)\n",
    "                        ]\n",
    "    dimensions=np.array(['L', 'A', 'G', 'T', 'P', 'K', 'S'])\n",
    "    \n",
    "    def __init__(self, t0=0, dt=1 , reward_type=None, image_dir=None, run_number=0, plot_progress=False,\n",
    "                 ics=dict(  L=2480.,  \n",
    "                            A=758.0,\n",
    "                            G=1125,\n",
    "                            T=5.053333333333333e-6,\n",
    "                            P=6e9,\n",
    "                            K=6e13,\n",
    "                            S=5e11\n",
    "                            ) , # ics defines the initial values!\n",
    "                 pars=dict( Sigma = 1.5 * 1e8,\n",
    "                            Cstar=5500,\n",
    "                            a0=0.03,\n",
    "                            aT=3.2*1e3,\n",
    "                            l0=26.4,\n",
    "                            lT=1.1*1e6,\n",
    "                            delta=0.01,\n",
    "                            m=1.5,\n",
    "                            g=0.02,\n",
    "                            p=0.04,\n",
    "                            Wp=2000,\n",
    "                            q0=20,\n",
    "                            b=5.4*1e-7,\n",
    "                            yE=147,\n",
    "                            eB=4*1e10,\n",
    "                            eF=4*1e10,\n",
    "                            i=0.25,\n",
    "                            k0=0.1,\n",
    "                            aY=0.,\n",
    "                            aB=3e5,\n",
    "                            aF=5e6,\n",
    "                            aR=7e-18,\n",
    "                            sS=1./50.,\n",
    "                            sR=1.,\n",
    "                            ren_sub=.5,\n",
    "                            carbon_tax=.5,\n",
    "                            i_DG=0.1,\n",
    "                            L0=0,\n",
    "                            )   , # pars contains the parameters for the global model\n",
    "                 specs=[] # contains specifications for the global model as e.g. the INST_GREENHOUSE  \n",
    "                 ):\n",
    "        \n",
    "        self.image_dir = image_dir\n",
    "        self.run_number = run_number\n",
    "        self.plot_progress = plot_progress\n",
    "        # The grid defines the number of cells, hence we have 8x8 possible states\n",
    "        self.final_state = False\n",
    "        self.reward = 0\n",
    "        \n",
    "        self.reward_function = self.get_reward_function(reward_type)\n",
    "        \n",
    "        timeStart = 0\n",
    "        intSteps = 10    # integration Steps\n",
    "        self.t = self.t0 = t0\n",
    "        self.dt = dt\n",
    "        \n",
    "        self.sim_time_step=np.linspace(timeStart,dt, intSteps)\n",
    "        \n",
    "        self.specs=specs\n",
    "        self.setParams(paramDict=pars)\n",
    "        self.setInitials(iniDict=ics)\n",
    "        \n",
    "        \n",
    "        # Definitions from outside\n",
    "        self.state=self.current_state=np.array([self.iniDynVar['L'], self.iniDynVar['A'], self.iniDynVar['G'], self.iniDynVar['T'], \n",
    "                                       self.iniDynVar['P'], self.iniDynVar['K'], self.iniDynVar['S'] \n",
    "                                       ])\n",
    "        self.state=self.start_state=self.current_state\n",
    "        self.Lprot=False\n",
    "        self.observation_space=self.state\n",
    "        \n",
    "        # Planetary Boundaries for A, Y, P (population!)\n",
    "        self.A_PB=945\n",
    "        self.A_scale=1\n",
    "        self.Y_PB=self.direct_Y(self.iniDynVar['L'], self.iniDynVar['G'], self.iniDynVar['P'], self.iniDynVar['K'], self.iniDynVar['S'])\n",
    "        self.P_PB=1e6\n",
    "        self.W_PB= (1- self.params['i'])*self.Y_PB / (1.01*self.iniDynVar['P'])   # Economic production in year 2000 and population in year 2000\n",
    "        self.W_scale=1e3\n",
    "        self.PB=np.array([self.A_PB, self.W_PB, self.P_PB])\n",
    "        self.compact_PB=compactification(self.PB, self.ini_state)    \n",
    "\n",
    "        self.P_scale=1e9\n",
    "        self.reward_type=reward_type\n",
    "        \n",
    "        print(\"Initialized c:GLOBAL environment!\" ,\n",
    "              \"\\nReward type: \" + str(reward_type),\n",
    "              \"\\nPlanetary Boundaries are: \" + str(self.PB),\n",
    "              \"\\nInitial LAGTPKS-values are: \" + str(self.ini_state),\n",
    "              \"\\nInitial derived values are: Wini:\"+str(self.Wini)+\"Yini: \"+str(self.Yini))\n",
    "        \n",
    "        self.color_list=['orangered', 'mediumvioletred', 'darkgreen', 'midnightblue', 'yellow', 'goldenrod', 'slategrey', 'olive' ] # Contains as many numbers as management options!\n",
    "\n",
    "    \"\"\"\n",
    "    This function is only basic function an Environment needs to provide\n",
    "    \"\"\"\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        This function performs one simulation step in a RFL algorithm. \n",
    "        It updates the state and returns a reward according to the chosen reward-function.\n",
    "        \"\"\"\n",
    "\n",
    "        next_t= self.t + self.dt\n",
    "        self._adjust_parameters(action)\n",
    "\n",
    "        \n",
    "        self.state=self._perform_step( next_t)\n",
    "        self.t=next_t\n",
    "        if self._arrived_at_final_state():\n",
    "            self.final_state = True\n",
    "        \n",
    "        reward=self.reward_function(action)\n",
    "        if not self._inside_planetary_boundaries():\n",
    "            self.final_state = True\n",
    "            #print(\"Left planetary boundaries!\" + str(self.state))\n",
    "        trafo_state=compactification(self.state, self.current_state)\n",
    "        #print(self.state, trafo_state)\n",
    "    #    return self.state, reward, self.final_state\n",
    "        return trafo_state, reward, self.final_state\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _perform_step(self, next_t):\n",
    "        \n",
    "        #print(parameter_list[0])\n",
    "        #print(self.state)\n",
    "        \n",
    "        traj_one_step=odeint(self.dDynVar, self.state, [self.t, next_t] , mxstep=50000)\n",
    "        l = traj_one_step[:,0][-1]\n",
    "        a = traj_one_step[:,1][-1]\n",
    "        g = traj_one_step[:,2][-1]\n",
    "        t = traj_one_step[:,3][-1]\n",
    "        p = traj_one_step[:,4][-1]\n",
    "        k = traj_one_step[:,5][-1]\n",
    "        s = traj_one_step[:,6][-1]\n",
    "        \n",
    "        #l,a,g,t,p,k,s= self.state\n",
    "\n",
    "        return np.array( (l,a,g,t,p,k,s) )\n",
    "    \n",
    "    \"\"\"\n",
    "    This functions are needed to reset the Environment to specific states\n",
    "    \"\"\"\n",
    "    def reset(self):\n",
    "        self.start_state=self.state=np.array(self.current_state_region_StartPoint())\n",
    "        trafo_state=compactification(self.state, self.current_state)\n",
    "\n",
    "        self.final_state=False\n",
    "        self.t=self.t0\n",
    "#        return self.state    \n",
    "        return trafo_state    \n",
    "    \n",
    "    \n",
    "    def reset_for_state(self, state=None):\n",
    "        if state==None:\n",
    "            self.start_state=self.state=self.current_state\n",
    "        else:\n",
    "            self.start_state=self.state=np.array(state)\n",
    "        self.final_state=False\n",
    "        self.t=self.t0\n",
    "        trafo_state=compactification(self.state, self.current_state)\n",
    "        \n",
    "        return trafo_state\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    This function defines the reward the Environment returns to the player for a given action\n",
    "    \"\"\"\n",
    "    def get_reward_function(self,choice_of_reward):\n",
    "        \"\"\"\n",
    "        This function returns one function as a function pointer according to the reward type we chose \n",
    "        for this simulation.\n",
    "        \"\"\"\n",
    "        def reward_final_state(action=0):\n",
    "            \"\"\"\n",
    "            Reward in the final  green fixpoint_good 100. , else 0.\n",
    "            \"\"\"\n",
    "            if self._good_final_state():\n",
    "                reward=2.\n",
    "            else:\n",
    "                if self._inside_planetary_boundaries():\n",
    "                    reward=1.\n",
    "                else:\n",
    "                    reward=0.\n",
    "            return reward\n",
    "        \n",
    "        def reward_ren_knowledge(action=0):\n",
    "            \"\"\"\n",
    "            We want to:\n",
    "            - maximize the knowledge stock of renewables S \n",
    "            \"\"\"\n",
    "            l,a,g,t,p,k,s = self.state\n",
    "            if self._inside_planetary_boundaries():\n",
    "                reward=compactification(s, self.iniDynVar['S'])\n",
    "            else:\n",
    "                reward=0.\n",
    "            \n",
    "            return reward       \n",
    "        def reward_desirable_region(action=0):\n",
    "            l,a,g,t,p,k,s = self.state\n",
    "            desirable_share_renewable=self.iniDynVar['S']\n",
    "            reward=0.\n",
    "            if s >= desirable_share_renewable:\n",
    "                reward=1.\n",
    "            return reward\n",
    "        \n",
    "        def reward_survive(action=0):\n",
    "            if self._inside_planetary_boundaries():\n",
    "                reward=1.\n",
    "            else:\n",
    "                reward=0.\n",
    "            return reward\n",
    "        \n",
    "        def reward_survive_cost(action=0):\n",
    "            cost_managment=0.03\n",
    "            if self._inside_planetary_boundaries():\n",
    "                reward=1.\n",
    "                if self.management_options[action] != 'default':\n",
    "                    reward -=cost_managment\n",
    "            else:\n",
    "                reward=-1e-30\n",
    "            \n",
    "            return reward\n",
    "        \n",
    "        def reward_distance_PB(action=0):\n",
    "            L,A,G,T,P,K,S=  self.state\n",
    "            Leff=L\n",
    "            if self.Lprot:\n",
    "                Leff=max(L-self.L0, 0)            \n",
    "            W=self.direct_W(Leff, G, P, K, S)\n",
    "            \n",
    "            #norm=np.linalg.norm(np.array([(A - self.A_PB)/Aini , (W-self.W_PB)/Wini, (P-self.P_PB)/Pini ]))\n",
    "            #norm = (self.state[0] - self.A_PB)**2 \n",
    "            if self._inside_planetary_boundaries():\n",
    "                norm=np.linalg.norm( self.compact_PB -  compactification( np.array([A, W, P]), self.ini_state))\n",
    "                #print(\"reward-function: \", norm)\n",
    "                reward=norm\n",
    "            else:\n",
    "                reward=0.\n",
    "            \n",
    "            return reward\n",
    "         \n",
    "        if choice_of_reward=='final_state':\n",
    "            return reward_final_state\n",
    "        elif choice_of_reward=='ren_knowledge':\n",
    "            return reward_ren_knowledge\n",
    "        elif choice_of_reward=='desirable_region':\n",
    "            return reward_desirable_region\n",
    "        elif choice_of_reward=='PB':\n",
    "            return reward_distance_PB\n",
    "        elif choice_of_reward=='survive':\n",
    "            return reward_survive\n",
    "        elif choice_of_reward=='survive_cost':\n",
    "            return reward_survive_cost\n",
    "        elif choice_of_reward==None:\n",
    "            print(\"ERROR! You have to choose a reward function!\\n\",\n",
    "                   \"Available Reward functions for this environment are: PB, rel_share, survive, desirable_region!\")\n",
    "        else:\n",
    "            print(\"ERROR! The reward function you chose is not available! \" + choice_of_reward)\n",
    "            print_debug_info()\n",
    "            sys.exit(1)\n",
    "   \n",
    "    \n",
    "    \"\"\"\n",
    "    This functions define the dynamics of the copan:GLOBAL model\n",
    "    \"\"\"\n",
    "    def dDynVar(self, LAGTPKS, t):\n",
    "        #auxiliary functions\n",
    "        #photosynthesis\n",
    "        def phot(L, A, T):\n",
    "            return (self.params['l0']-self.params['lT']*T)*np.sqrt(A)/np.sqrt(self.params['Sigma'])\n",
    "        #respiration\n",
    "        def resp(L, T):\n",
    "            return self.params['a0']+self.params['aT']*T\n",
    "        #diffusion atmosphere <--> ocean\n",
    "        def diff(L, A, G=0.):\n",
    "            return self.params['delta']*(self.params['Cstar']-L-G-(1+self.params['m'])*A)\n",
    "        \n",
    "        def fert(P,W):\n",
    "            return 2*self.params['p']*self.params['Wp']*W/(self.params['Wp']**2+W**2) \n",
    "    \n",
    "        def mort(P,W):\n",
    "            return self.params['q0']/(W) + self.params['qP']*P/self.params['Sigma']\n",
    "        \n",
    "        \n",
    "        L, A, G, T, P, K, S= LAGTPKS\n",
    "        #adjust to lower and upper bounds\n",
    "        L=np.amin([np.amax([L, 1e-12]), self.params['Cstar']])\n",
    "        A=np.amin([np.amax([A, 1e-12]), self.params['Cstar']])\n",
    "        G=np.amin([np.amax([G, 1e-12]), self.params['Cstar']])\n",
    "        T=np.amax([T, 1e-12])\n",
    "        P=np.amax([P, 1e-12])\n",
    "        K=np.amax([K, 1e-12])\n",
    "        S=np.amax([S, 1e-12])\n",
    "\n",
    "        # calculate T and A if instantaneous processes\n",
    "        if 'INST_DIFF' in self.specs:\n",
    "            A = (self.params['Cstar']-L-G) / (1.+self.params['m'])\n",
    "        if 'INST_GH' in self.specs:\n",
    "            T = A/self.params['Sigma']\n",
    "        #calculate auxiliary quantities\n",
    "        \n",
    "        if self.Lprot:\n",
    "            Leff=max(L-self.L0, 0)\n",
    "        else:\n",
    "            Leff=L\n",
    "        Xb=self.params['aB']*Leff**2.\n",
    "        Xf=self.params['aF']*G**2.\n",
    "        Xr=self.params['aR']*S**2. \n",
    "        X=Xb+Xf+Xr\n",
    "        \n",
    "        expP=2./5.\n",
    "        expK=2./5.\n",
    "        if 'KproptoP' in self.specs:\n",
    "#             expP=4./5.\n",
    "#             expK=0.\n",
    "            K = P*self.iniDynVar['K']/(self.iniDynVar['P'])\n",
    "        if 'NproptoP' in self.specs:\n",
    "            expP-=1./5.   # gives in combination expP=3./5\n",
    "        Z=self.Z(P, K, X, expP, expK)\n",
    "        \n",
    "        #calculate derived variables\n",
    "        B=self.B(Xb, Z)\n",
    "        F=self.F(Xf, Z)\n",
    "        R=self.R(Xr, Z)\n",
    "\n",
    "        Y=self.Y(B, F, R)\n",
    "        W=self.W(Y, P, L)\n",
    "\n",
    "        #calculate derivatives of the dynamic variables\n",
    "        dL = (phot(L, A, T) - resp(L, T)) * L - B\n",
    "        #print(self.phot(L, A, T) *L  , self.resp(L, T)*L , B , T)\n",
    "        dA = -dL + diff(L, A, G)\n",
    "        dG = -F\n",
    "        dT = self.params['g'] * (A/self.params['Sigma'] - T)\n",
    "        dP = P * (fert(P,W)-mort(P,W))\n",
    "        dK = self.params['i'] * Y - self.params['k0'] * K\n",
    "        dS = self.params['sR']*R - self.params['sS']*S\n",
    "\n",
    "        if 'INST_DIFF' in self.specs:\n",
    "            dA = -(dL+dG)/(1.+self.params['m'])\n",
    "        if 'INST_GH' in self.specs:\n",
    "            dT = dA/self.params['Sigma']\n",
    "        \n",
    "        #print(t, self.Lprot, L,  self.L0 , Leff, B, phot(L, A, T) , resp(L, T) )\n",
    "        #print(Y, K, self.params['i'], self.params['k0'], dK)\n",
    "        #print(R, S, self.params['sS'], dS)\n",
    "        #print(W, P, dP)\n",
    "        return [dL, dA, dG, dT, dP, dK, dS]        \n",
    "\n",
    "    def setInitials(self,iniDict):\n",
    "        self.iniDynVar=OrderedDict()\n",
    "        if 'L' in iniDict.keys():\n",
    "            L = iniDict['L']\n",
    "            try:\n",
    "                assert 0 <= L <= self.params['Cstar'], \"L must be between 0 and Cstar\"\n",
    "                try: assert L <= self.params['Cstar'] - self.iniDynVar['A'], \"L must be <= Cstar - A\"\n",
    "                except: pass\n",
    "            except: pass\n",
    "            self.iniDynVar['L'] = L\n",
    "        \n",
    "        if 'A' in iniDict.keys():\n",
    "            A = iniDict['A']\n",
    "            try:\n",
    "                assert 0 <= A <= self.params['Cstar'], \"A must be between 0 and Cstar\"\n",
    "                try: assert A <= self.params['Cstar'] - self.iniDynVar['L'], \"A must be <= Cstar - L\"\n",
    "                except: pass\n",
    "            except: pass\n",
    "            self.iniDynVar['A'] = A\n",
    "        \n",
    "        if 'G' in iniDict.keys():\n",
    "            G = iniDict['G']\n",
    "            try:\n",
    "                assert 0 <= G <= self.params['Cstar'], \"G must be between 0 and Cstar\"\n",
    "            except: pass\n",
    "            self.iniDynVar['G'] = G\n",
    "            \n",
    "        if 'T' in iniDict.keys():\n",
    "            T = iniDict['T']\n",
    "            try:\n",
    "                assert 0 <= T, \"T must be non-negative\"\n",
    "            except: pass\n",
    "            self.iniDynVar['T'] = T\n",
    "        \n",
    "        if 'P' in iniDict.keys():\n",
    "            P = iniDict['P']\n",
    "            try:\n",
    "                assert 0 <= P, \"P must be non-negative\"\n",
    "            except: pass\n",
    "            self.iniDynVar['P'] = P\n",
    "            \n",
    "        if 'K' in iniDict.keys():\n",
    "            K = iniDict['K']\n",
    "            try:\n",
    "                assert 0 <= K, \"K must be non-negative\"\n",
    "            except: pass\n",
    "            self.iniDynVar['K'] = K\n",
    "        \n",
    "        if 'S' in iniDict.keys():\n",
    "            S = iniDict['S']\n",
    "            try:\n",
    "                assert 0 <= S, \"S must be non-negative\"\n",
    "            except: pass\n",
    "            self.iniDynVar['S'] = S\n",
    "            \n",
    "        self.Aini=self.iniDynVar['A']\n",
    "        self.Pini=self.iniDynVar['P']\n",
    "        \n",
    "        \n",
    "        Xb=self.params['aB']*self.iniDynVar['L']**2.\n",
    "        Xf=self.params['aF']*self.iniDynVar['G']**2.\n",
    "        Xr=self.params['aR']*self.iniDynVar['S']**2. \n",
    "        X=Xb+Xf+Xr\n",
    "        \n",
    "        expP=2./5.\n",
    "        expK=2./5.\n",
    "        Z=self.Z(self.iniDynVar['P'], self.iniDynVar['K'], X, expP, expK)\n",
    "        \n",
    "        #calculate derived variables\n",
    "        self.Bini=self.B(Xb, Z)\n",
    "        self.Fini=self.F(Xf, Z)\n",
    "        self.Rini=self.R(Xr, Z)\n",
    "\n",
    "        self.Yini=self.Y(self.Bini, self.Fini, self.Rini)\n",
    "        self.Wini=self.W(self.Yini, self.Pini, self.iniDynVar['L'])\n",
    "        \n",
    "        self.ini_state=np.array([self.Aini, self.Wini, self.Pini])\n",
    "            \n",
    "    def setParams(self,paramDict):\n",
    "        self.params={}\n",
    "        if 'Cstar' in paramDict.keys():\n",
    "            Cstar = paramDict['Cstar']\n",
    "            assert 0 < Cstar, \"Cstar must be positive\"\n",
    "            self.params['Cstar']=Cstar\n",
    "            \n",
    "        if 'Sigma' in paramDict.keys():\n",
    "            Sigma = paramDict['Sigma']\n",
    "            assert 0 < Sigma, \"Sigma must be positive\"\n",
    "            self.params['Sigma'] = Sigma \n",
    "            \n",
    "        if 'm' in paramDict.keys():\n",
    "            m = paramDict['m']\n",
    "            assert 0 < m, \"m must be positive\"\n",
    "            self.params['m'] = m\n",
    "        \n",
    "        if 'a0' in paramDict.keys():\n",
    "            a0 = paramDict['a0']\n",
    "            assert 0 <= a0, \"a0 must be non-negative\"\n",
    "            self.params['a0'] = a0\n",
    "            \n",
    "        if 'aT' in paramDict.keys():\n",
    "            aT = paramDict['aT']\n",
    "            assert 0 <= aT, \"aT must be non-negative\"\n",
    "            self.params['aT'] = aT\n",
    "        \n",
    "        if 'l0' in paramDict.keys():\n",
    "            l0 = paramDict['l0']\n",
    "            assert 0 <= l0, \"l0 must be non-negative\"\n",
    "            self.params['l0'] = l0\n",
    "            \n",
    "        if 'lT' in paramDict.keys():\n",
    "            lT = paramDict['lT']\n",
    "            assert 0 <= lT, \"lT must be non-negative\"\n",
    "            self.params['lT'] = lT\n",
    "        \n",
    "        if 'delta' in paramDict.keys():\n",
    "            delta = paramDict['delta']\n",
    "            assert 0 < delta, \"delta must be positive\"\n",
    "            self.params['delta'] = delta\n",
    " \n",
    "        if 'g' in paramDict.keys():\n",
    "            g = paramDict['g']\n",
    "            assert 0 < g, \"g must be positive\"\n",
    "            self.params['g'] = g\n",
    "        \n",
    "        if 'p' in paramDict.keys():\n",
    "            p = paramDict['p']\n",
    "            assert 0 <= p, \"p must be non-negative\"\n",
    "            self.params['p'] = p\n",
    "        \n",
    "        if 'q0' in paramDict.keys():\n",
    "            q0 = paramDict['q0']\n",
    "            assert 0 <= q0, \"p must be non-negative\"\n",
    "            self.params['q0'] = q0\n",
    "        \n",
    "        if 'qP' in paramDict.keys():\n",
    "            qP = paramDict['qP']\n",
    "            assert 0 <= qP, \"p must be non-negative\"\n",
    "            self.params['qP'] = qP\n",
    "        \n",
    "        if 'Wp' in paramDict.keys():\n",
    "            Wp = paramDict['Wp']\n",
    "            assert 0 <= Wp, \"p must be non-negative\"\n",
    "            self.params['Wp'] = Wp\n",
    "            \n",
    "        if 'yE' in paramDict.keys():\n",
    "            yE = paramDict['yE']\n",
    "            assert 0 <= yE, \"p must be non-negative\"\n",
    "            self.params['yE'] = yE\n",
    "            \n",
    "        if 'wL' in paramDict.keys():\n",
    "            wL = paramDict['wL']\n",
    "            assert 0 <= wL, \"p must be non-negative\"\n",
    "            self.params['wL'] = wL\n",
    "            \n",
    "        if 'eB' in paramDict.keys():\n",
    "            eB = paramDict['eB']\n",
    "            assert 0 <= eB, \"eB must be non-negative\"\n",
    "            self.params['eB'] = eB\n",
    "            \n",
    "        if 'eF' in paramDict.keys():\n",
    "            eF = paramDict['eF']\n",
    "            assert 0 <= eF, \"eF must be non-negative\"\n",
    "            self.params['eF'] = eF       \n",
    "            \n",
    "        if 'aY' in paramDict.keys():\n",
    "            aY = paramDict['aY']\n",
    "            assert 0 <= aY, \"aY must be non-negative\"\n",
    "            self.params['aY'] = aY\n",
    "\n",
    "        if 'aB' in paramDict.keys():\n",
    "            aB = paramDict['aB']\n",
    "            assert 0 <= aB, \"aB must be non-negative\"\n",
    "            self.params['aB'] = aB\n",
    "\n",
    "        if 'aF' in paramDict.keys():\n",
    "            aF = paramDict['aF']\n",
    "            assert 0 <= aF, \"aF must be non-negative\"\n",
    "            self.params['aF'] = aF\n",
    "        \n",
    "        if 'aR' in paramDict.keys():\n",
    "            aR = paramDict['aR']\n",
    "            assert 0 <= aR, \"aR must be non-negative\"\n",
    "            self.params['aR'] = aR\n",
    "        \n",
    "        if 'i' in paramDict.keys():\n",
    "            i = paramDict['i']\n",
    "            assert 0 <= i <= 1., \"i must be between 0 and 1\"\n",
    "            self.params['i'] = i\n",
    "        \n",
    "        if 'k0' in paramDict.keys():\n",
    "            k0 = paramDict['k0']\n",
    "            assert 0 <= k0, \"k0 must be non-negative\"\n",
    "            self.params['k0'] = k0\n",
    "        \n",
    "        if 'sR' in paramDict.keys():\n",
    "            sR = paramDict['sR']\n",
    "            assert 0 <=sR , \"sR must be non-negative\"\n",
    "            self.params['sR']=sR\n",
    "        \n",
    "        if 'sS' in paramDict.keys():\n",
    "            sS = paramDict['sS']\n",
    "            assert 0 <=sS , \"sS must be non-negative\"\n",
    "            self.params['sS']=sS\n",
    "            \n",
    "        if 'ren_sub' in paramDict.keys():\n",
    "            ren_sub=paramDict['ren_sub']\n",
    "        if 'carbon_tax' in paramDict.keys():\n",
    "            carbon_tax=paramDict['carbon_tax']\n",
    "        if 'i_DG' in paramDict.keys():\n",
    "            i_DG=paramDict['i_DG']\n",
    "        if 'L0' in paramDict.keys():\n",
    "            L0=paramDict['L0']\n",
    "            \n",
    "            \n",
    "        # Here default parameters before management is used\n",
    "        self.aR_default=aR\n",
    "        self.aB_default=aB\n",
    "        self.aF_default=aF\n",
    "        self.i_default=i\n",
    "        \n",
    "        self.L0=L0\n",
    "        \n",
    "        self.ren_sub=ren_sub\n",
    "        self.carbon_tax=carbon_tax\n",
    "        self.i_DG=i_DG\n",
    "    \n",
    "    # maritime stock\n",
    "    \n",
    "    def M(self, L, A, G):\n",
    "        return self.params['Cstar']-L-A-G\n",
    "    #economic production\n",
    "    def Y(self, B, F, R):\n",
    "        #return self.params['y'] * ( self.params['eB']*B + self.params['eF']*F )\n",
    "        # Y = y * E     E = E_B + E_F + R\n",
    "        return self.params['yE'] * ( self.params['eB']*B + self.params['eF']*F + R )\n",
    "    #wellbeing\n",
    "    def W(self, Y, P, L):\n",
    "        return (1.-self.params['i']) * Y / P + self.params['wL']*L/self.params['Sigma']\n",
    "    # energy sector\n",
    "    #auxiliary\n",
    "    def Z(self, P, K, X, expP=2./5, expK=2./5.):\n",
    "        return P**expP * K**expK / X**(4./5.)\n",
    "        \n",
    "    def B(self, Xb, Z):\n",
    "        return Xb * Z / self.params['eB']\n",
    "    def F(self, Xf, Z):\n",
    "        return Xf * Z / self.params['eF']\n",
    "    def R(self,Xr, Z):\n",
    "        return Xr * Z \n",
    "    \n",
    "    def direct_Y(self, L,G,P,K,S):\n",
    "        Xb=self.params['aB']*L**2.\n",
    "        Xf=self.params['aF']*G**2.\n",
    "        Xr=self.params['aR']*S**2.  \n",
    "        X=Xb+Xf+Xr\n",
    "        \n",
    "        expP=2./5.\n",
    "        expK=2./5.\n",
    "        if 'KproptoP' in self.specs:\n",
    "#             expP=4./5.\n",
    "#             expK=0.\n",
    "            K = P*self.iniDynVar['K']/(self.iniDynVar['P'])\n",
    "        if 'NproptoP' in self.specs:\n",
    "            expP-=1./5.   # gives in combination expP=3./5\n",
    "        Z=self.Z(P, K, X, expP, expK)           \n",
    "        B=self.B(Xb, Z)\n",
    "        F=self.F(Xf, Z)\n",
    "        R=self.R(Xr, Z)\n",
    "        return self.Y(B, F, R)\n",
    "    \n",
    "    def direct_W(self,L,G,P,K,S):\n",
    "        Y=self.direct_Y(L, G, P, K, S)\n",
    "        return self.W(Y, P, L)\n",
    "    \n",
    "    def get_Aini(self,Lini, Gini):\n",
    "        return (self.params['Cstar']-Lini-Gini)/(1.+self.params['m'])\n",
    "        \n",
    "    def get_Tini(self,Aini):\n",
    "        return Aini/self.params['Sigma']\n",
    "    \n",
    "    def prepare_action_set(self, state):\n",
    "        this_state_action_set=[]\n",
    "        L, A, G, T, P, K, S= state\n",
    "        for idx in range(len(self.action_space)):\n",
    "            self._adjust_parameters(idx)\n",
    "            W=self.direct_W(L, G, P, K, S)\n",
    "            if W > self.W_PB:\n",
    "                this_state_action_set.append(idx)\n",
    "        return this_state_action_set\n",
    "    def _adjust_parameters(self, action_number=0):\n",
    "        \"\"\"\n",
    "        This function is needed to adjust the parameter set for the chosen management option.\n",
    "        Here the action numbers are really transformed to parameter lists, according to the chosen \n",
    "        management option.\n",
    "        Parameters:\n",
    "            -action: Number of the action in the actionset.\n",
    "             Can be transformed into: 'default', 'subsidy' 'carbon tax' 'Nature Protection ' or possible combinations\n",
    "        \"\"\"\n",
    "        if action_number < len(self.action_space):\n",
    "            action=self.action_space[action_number]\n",
    "        else:\n",
    "            print(\"ERROR! Management option is not available!\" + str (action))\n",
    "            print(get_linenumber())\n",
    "            sys.exit(1)\n",
    "        # subsidy \n",
    "        if action[0]:\n",
    "            self.params['aR']=self.aR_default*(1+self.ren_sub) \n",
    "        else:\n",
    "            self.params['aR']=self.aR_default\n",
    "        # carbon tax\n",
    "        if action[1]:\n",
    "            self.params['aB']=self.aB_default*(1-self.carbon_tax)\n",
    "            self.params['aF']=self.aF_default*(1-self.carbon_tax)\n",
    "        else:\n",
    "            self.params['aB']=self.aB_default\n",
    "            self.params['aF']=self.aF_default          \n",
    "        # nature protection\n",
    "        if action[2]:\n",
    "            self.Lprot=True\n",
    "        else:\n",
    "            self.Lprot=False\n",
    "    \n",
    "    \"\"\"\n",
    "    This functions are needed to define a final state and to cluster to Green or brown FP\n",
    "    \"\"\"\n",
    "    def _inside_planetary_boundaries(self):\n",
    "        L,A,G,T,P,K,S = self.state\n",
    "        Leff=L\n",
    "        if self.Lprot:\n",
    "            Leff=max(L-self.L0, 0)\n",
    "        W=self.direct_W(Leff, G, P, K, S)\n",
    "        \n",
    "        is_inside = True\n",
    "        if A > self.A_PB or W < self.W_PB or P<self.P_PB:\n",
    "            is_inside = False\n",
    "            #print(\"Outside PB!\")\n",
    "        return is_inside\n",
    "    \n",
    "        \n",
    "    \"\"\"\n",
    "    This functions are specific to sustainable management parameters, to decide whether we are inside/outside of planetary boundaries\n",
    "    and whether the game is finished or not!\n",
    "    \"\"\"\n",
    "    def current_state_region_StartPoint(self):\n",
    "        \n",
    "        self.state=np.ones(7)\n",
    "        self._adjust_parameters(0)\n",
    "        while not self._inside_planetary_boundaries(): \n",
    "            #self.state=self.current_state + np.random.uniform(low=-limit_start, high=limit_start, size=3)\n",
    "            lower_limit=-.1\n",
    "            upper_limit=.1\n",
    "            rnd= np.random.uniform(low=lower_limit, high=upper_limit, size=(len(self.state),))\n",
    "            self.state[0] = self.current_state[0] + 1e3*rnd[0]  #L\n",
    "            self.state[1] = self.current_state[1] + 1e3*rnd[1]  #A\n",
    "            self.state[2] = self.current_state[2] + 1e3*rnd[2]  #G\n",
    "            \n",
    "            self.state[3] = self.get_Tini(self.state[1])        # T\n",
    "            self.state[4] = self.current_state[4] + 1e9*rnd[4]  # P\n",
    "            self.state[5] = self.current_state[5] + 1e13*rnd[5] # K \n",
    "            self.state[6] = self.current_state[6] + 1e11*rnd[6] # S\n",
    "            \n",
    "        return self.state\n",
    "\n",
    "        \n",
    "    def  _arrived_at_final_state(self):\n",
    "        L,A,G,T,P,K,S=self.state\n",
    "        # Attention that we do not break up to early since even at large W it is still possible that A_PB is violated!\n",
    "        if self.A_PB - A > 0 and self.direct_W(L, G, P, K, S) > 2.e6 and P > 1e10 and self.t>400:\n",
    "            #print(\"end\", self.t)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "              \n",
    "    def _good_final_state(self):\n",
    "        L,A,G,T,P,K,S=self.state\n",
    "        # Good Final State. TODO find a reasonable explanation for this values (maybe something like carbon budget...)!\n",
    "        if self.A_PB - A > 60 and self.direct_W(L, G, P, K, S) > 2.8e6 and P > 1e10  :\n",
    "            #print('Success!')\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def _which_final_state(self):\n",
    "        l,a,g,t,p,k,s=self.state\n",
    "        if self._inside_planetary_boundaries():\n",
    "            #print(\"ARRIVED AT GREEN FINAL STATE WITHOUT VIOLATING PB!\")\n",
    "            return Basins.GREEN_FP\n",
    "        else:\n",
    "            return Basins.OUT_PB\n",
    "    \n",
    "    def get_plot_state_list(self):\n",
    "        trafo_state=compactification(self.state, self.current_state)\n",
    "\n",
    "        return trafo_state.tolist()\n",
    "    \n",
    "    def observed_states(self):\n",
    "        return self.dimensions\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c36de13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
